{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "840efa66-125e-4e8e-9986-a0ae0772d681",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from model import addGPT  \n",
    "from model import encode, decode  ,num_digits,val_data\n",
    "device1 =  device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "saved_model = 'addition_weights.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a4eeea78-6177-4a8c-b2c5-11f3310ecb1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully loaded weights from addition_weights.pth\n",
      "Enter 'q' or 'quit' to exit\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter first number:  9548357757\n",
      "Enter second number:  5890543975\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Problem: 9548357757 + 5890543975\n",
      "Model's Answer: 15438901732\n",
      "Actual Answer: 15438901732\n",
      "Model predicted correctly\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Try another problem? (y/n):  y\n",
      "\n",
      "Enter first number:  2939\n",
      "Enter second number:  546\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Problem: 2939 + 546\n",
      "Model's Answer: 3485\n",
      "Actual Answer: 3485\n",
      "Model predicted correctly\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Try another problem? (y/n):  0\n"
     ]
    }
   ],
   "source": [
    "def initialize_model(model_path=saved_model, device=device1):\n",
    "    \n",
    "    model = addGPT(train=False)  \n",
    "    model.to(device)\n",
    "    \n",
    "    try:\n",
    "        model.load_state_dict(torch.load(model_path))\n",
    "        print(f\"\\nSuccessfully loaded weights from {model_path}\")\n",
    "        model.eval()\n",
    "        return model\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading weights: {e}\")\n",
    "        return None\n",
    "\n",
    "def run_inference():\n",
    "\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model = initialize_model()\n",
    "    if model is None:\n",
    "        return\n",
    "    print(\"Enter 'q' or 'quit' to exit\")\n",
    "    \n",
    "    while True:\n",
    "    \n",
    "        while True:\n",
    "            num1 = input(\"\\nEnter first number: \").strip()\n",
    "            if num1.lower() in ['q', 'quit']:\n",
    "                \n",
    "                return\n",
    "            if num1.isdigit() and len(num1) <= num_digits:\n",
    "                num1 = num1.zfill(num_digits)\n",
    "                break\n",
    "            print(f'Please enter a valid number up to {num_digits} digits.')\n",
    "        \n",
    "        while True:\n",
    "            num2 = input(\"Enter second number: \").strip()\n",
    "            if num2.lower() in ['q', 'quit']:\n",
    "                \n",
    "                return\n",
    "            if num2.isdigit() and len(num2) <= num_digits:\n",
    "                num2 = num2.zfill(num_digits)\n",
    "                break\n",
    "            print(f'Please enter a valid number up to {num_digits} digits.')\n",
    "        \n",
    "        problem = num1 + num2\n",
    "        problem_tokens = encode(problem)\n",
    "        problem_tensor = torch.tensor(problem_tokens, dtype=torch.long).unsqueeze(0).to(device)\n",
    "        \n",
    "        \n",
    "        with torch.no_grad():\n",
    "            generated_tokens = model.generate(\n",
    "                problem_tensor,\n",
    "                max_new_tokens=num_digits+1\n",
    "            )\n",
    "        \n",
    "        # Process output\n",
    "        predicted_answer = decode(generated_tokens[0].tolist())[-(num_digits+1):]\n",
    "        predicted_answer = predicted_answer[::-1]\n",
    "        \n",
    "        # Calculate actual answer\n",
    "        actual_answer = str(int(num1) + int(num2)).zfill(num_digits+1)\n",
    "        \n",
    "        \n",
    "        print(\"\\nProblem:\", f\"{int(num1)} + {int(num2)}\")\n",
    "        print(\"Model's Answer:\", int(predicted_answer))\n",
    "        print(\"Actual Answer:\", int(actual_answer))\n",
    "        \n",
    "        if int(predicted_answer) == int(actual_answer):\n",
    "            print(\"Model predicted correctly\")\n",
    "        else:\n",
    "            print(\"Model prediction was incorrect\")\n",
    "        \n",
    "        \n",
    "        cont = input(\"\\nTry another problem? (y/n): \").strip().lower()\n",
    "        if cont != 'y':\n",
    "            break\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_inference()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e1c6cce8-14e3-4cc0-8f1a-f56a355bfd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_val(model, num_samples=1000):\n",
    "    model.eval()\n",
    "    correct_predictions = 0\n",
    "    incorrect_predictions = 0\n",
    "    evaluation_samples = random.sample(val_data, min(num_samples, len(val_data)))\n",
    "    progress_bar = tqdm(evaluation_samples, \n",
    "                       desc=\"Evaluating model\",\n",
    "                       unit=\"sample\",\n",
    "                       total=len(evaluation_samples))\n",
    "    for eqn in progress_bar:\n",
    "        #correct format from val\n",
    "        problem_tokens = encode(eqn[:(2*num_digits)]) \n",
    "        problem_tensor = torch.tensor(problem_tokens, dtype=torch.long).unsqueeze(0).to(device)\n",
    "       \n",
    "        generated_tokens = model.generate(\n",
    "            problem_tensor,\n",
    "            max_new_tokens = num_digits+1\n",
    "        )\n",
    "        \n",
    "        predicted_answer = decode(generated_tokens[0].tolist())[-(num_digits+1):]\n",
    "        predicted_answer = predicted_answer[::-1]\n",
    "        # Calculate the actual answer\n",
    "        actual_answer = eqn[(2*num_digits):]\n",
    "        actual_answer = actual_answer[::-1]\n",
    "        if predicted_answer == actual_answer:\n",
    "            correct_predictions += 1\n",
    "           \n",
    "        else:\n",
    "            incorrect_predictions += 1\n",
    "            if(incorrect_predictions<10):\n",
    "                print(f'Incorrect Prediction : {eqn[:num_digits]} + {eqn[num_digits:2*num_digits]} = {predicted_answer} | {actual_answer}')\n",
    "    current_accuracy = (correct_predictions / (correct_predictions + incorrect_predictions)) * 100\n",
    "    progress_bar.set_description(f\"Evaluating model (Accuracy: {current_accuracy:.2f}%)\")\n",
    "    total_samples = correct_predictions + incorrect_predictions\n",
    "    accuracy = (correct_predictions / total_samples) * 100 if total_samples > 0 else 0\n",
    "\n",
    "    print(f\"Evaluation Summary:\")\n",
    "    print(f\"  Total Samples: {total_samples}\")\n",
    "    print(f\"  Correct Predictions: {correct_predictions}\")\n",
    "    print(f\"  Incorrect Predictions: {incorrect_predictions}\")\n",
    "    print(f\"  Accuracy: {accuracy:.4f}%\")\n",
    "    \n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1104b28f-e5cb-4a9a-adb3-71c47b83a5cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully loaded weights from addition_weights.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating model:   4%|██▎                                                        | 39/1000 [00:05<02:00,  7.98sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5450279056 + 6910234450 = 12360513406 | 12360513506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating model:   8%|████▍                                                      | 76/1000 [00:10<02:12,  6.97sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9834372352 + 8718111147 = 18552493499 | 18552483499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating model:   9%|█████▌                                                     | 94/1000 [00:12<01:57,  7.71sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4666137419 + 3844376482 = 08510513911 | 08510513901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating model:  11%|██████▍                                                   | 111/1000 [00:14<02:00,  7.40sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7221870788 + 6521662839 = 13743433627 | 13743533627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating model:  15%|████████▍                                                 | 146/1000 [00:19<01:36,  8.85sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2979641338 + 2303721220 = 06283362558 | 05283362558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating model:  20%|███████████▋                                              | 201/1000 [00:26<01:42,  7.76sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8841017378 + 9010116415 = 17951133793 | 17851133793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating model:  23%|█████████████▏                                            | 228/1000 [00:30<01:55,  6.67sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5612620385 + 3981924009 = 08594544394 | 09594544394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating model:  30%|█████████████████▎                                        | 298/1000 [00:40<01:26,  8.10sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6370535540 + 1995663414 = 08365198954 | 08366198954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating model:  33%|███████████████████                                       | 329/1000 [00:44<01:22,  8.14sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9579555043 + 5031974464 = 14611529407 | 14611529507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating model: 100%|█████████████████████████████████████████████████████████| 1000/1000 [02:13<00:00,  7.50sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Summary:\n",
      "  Total Samples: 1000\n",
      "  Correct Predictions: 977\n",
      "  Incorrect Predictions: 23\n",
      "  Accuracy: 97.7000%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = initialize_model()\n",
    "evaluate_model_val(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd46353e-2e37-4c73-a897-770b508eddac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
