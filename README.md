# AddGPT

**AddGPT** is a PyTorch implementation of a decoder-only Transformer model implemented from scratch with minimal dependencies, inspired by the "Attention is All You Need" paper. 
The model is trained with only 399k parameters and capable of performing addition between any two numbers, each up to 10 digits long, with 97.5% accuracy 
It demonstrates the capability of transformer architectures to learn and execute mathematical operations without relying on traditional arithmetic algorithms.